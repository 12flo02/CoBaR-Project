{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal, fftpack, stats\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieve folders for transgenic strains\n",
    "\n",
    "transgenics = os.listdir('CoBar-Dataset')\n",
    "transgenics.remove('PR') # Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(xp):\n",
    "    '''\n",
    "    Load data from an experiment (xp)\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    gen_dict\n",
    "        General info on data (on/off periods, collisions...)\n",
    "    \n",
    "    data\n",
    "        Raw data\n",
    "    \n",
    "    metadata\n",
    "        Raw metadata\n",
    "    '''\n",
    "    \n",
    "    # Load gendict\n",
    "    genDict = np.load(f'CoBar-Dataset/{xp}/U3_f/genotype_dict.npy', allow_pickle=True).item()\n",
    "    \n",
    "    # Load data\n",
    "    with open(f'CoBar-Dataset/{xp}/U3_f/{xp}_U3_f_trackingData.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    print(f'{xp} - Data dimension: {data.shape}')\n",
    "    \n",
    "    # Extract metadata\n",
    "    metadata = np.array([list(item) for item in data.index.values])\n",
    "    print(f'{xp} - Metadata dimension: {metadata.shape}')\n",
    "    \n",
    "    return genDict, data, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data_per_fly_per_xp():  \n",
    "    '''\n",
    "    Extract data for each fly in each experiment\n",
    "    \n",
    "    N: number of flies\n",
    "    L: number of frames\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    dict_pretarsi_data\n",
    "        A dictionary containing xy data for each pretarsus for each fly, size Lx12 for each fly\n",
    "        key = experiment + fly index (according to tracking video)\n",
    "    \n",
    "    dict_metadata\n",
    "        Corresponding metadata, size Lx6 for each fly\n",
    "        key = experiment + fly index (according to tracking video)\n",
    "    \n",
    "    dict_pos_data\n",
    "        Centroid xy data, size Lx2 for each fly\n",
    "        key = experiment + fly index (according to tracking video)\n",
    "    \n",
    "    n_trial_data\n",
    "        Get number of flies in each experiment\n",
    "        key = experiment\n",
    "    '''\n",
    "    \n",
    "    dict_pretarsi_data = {}\n",
    "    dict_metadata = {}\n",
    "    dict_pos_data = {}\n",
    "    n_trial_data = {}\n",
    "    \n",
    "    stim_col = 1 # Metadata column with stimulation info ('on'/'off')\n",
    "    xp_col = 3   # Metadata column with experiment info (time of experiment)\n",
    "    fly_col = 4  # Metadata column with fly info (fly 0, 1 or 2) \n",
    "    \n",
    "    for strain in transgenics:\n",
    "        # Load data for given strain\n",
    "        genDict, data, metadata = load_data(strain)\n",
    "        \n",
    "        # Extract pretarsi data\n",
    "        pretarsi = [\"LFclaw\", \"LHclaw\", \"LMclaw\", \"RFclaw\", \"RHclaw\", \"RMclaw\"]\n",
    "        pos = [\"posx\", \"posy\"]\n",
    "        orientation = [\"orientation\"]\n",
    "        pretarsi_data = data[pretarsi]   \n",
    "        pos_data = data[\"center\"][pos + orientation]\n",
    "    \n",
    "        # Gather all possible experiments and maximum number of flies\n",
    "        xps = np.unique(metadata[:,xp_col])\n",
    "        flies = np.unique(metadata[:,fly_col])\n",
    "        \n",
    "        n_trials = len(xps)*len(flies)\n",
    "\n",
    "        for xp in xps:\n",
    "            # Extract rows corresponding to current experiment\n",
    "            xp_idx = np.where(metadata[:,xp_col] == xp)[0]\n",
    "            \n",
    "            # Extract corresponding metadata, pretarsi data and positional data\n",
    "            xp_metadata = metadata[xp_idx]\n",
    "            xp_pretarsi_data = pretarsi_data.iloc[xp_idx]\n",
    "            xp_pos_data = pos_data.iloc[xp_idx]\n",
    "\n",
    "            for fly in flies:\n",
    "                # Extract rows corresponding to current fly\n",
    "                fly_idx = np.where(xp_metadata[:,fly_col] == fly)[0]\n",
    "                \n",
    "                # Extract corresponding metadata and data for current fly\n",
    "                xp_fly_metadata = xp_metadata[fly_idx]\n",
    "                xp_fly_pretarsi_data = xp_pretarsi_data.iloc[fly_idx]\n",
    "                xp_fly_pos_data = xp_pos_data.iloc[fly_idx]\n",
    "                \n",
    "                xp_fly_metadata = np.append(xp_fly_metadata, np.array(range(len(xp_fly_metadata))).reshape(-1,1), axis=1)\n",
    "                \n",
    "                \n",
    "                # Sort timestamps, and re-arrange fly data for time stamps\n",
    "                # Order = 'off0', 'on0', 'off1', 'on1', 'off2', 'on2', 'off3'\n",
    "                if not(xp_fly_pretarsi_data.empty):\n",
    "                    \n",
    "                    dict_metadata[xp+fly] = np.array(sorted(xp_fly_metadata, key=lambda x: (int(x[stim_col][-1]), x[stim_col])))\n",
    "                    idx_sort = np.array(list(map(int, dict_metadata[xp+fly][:,-1])))\n",
    "                    dict_pretarsi_data[xp + fly] = np.array(xp_fly_pretarsi_data)[idx_sort,:] * 38/832                    \n",
    "                    dict_pos_data[xp + fly] = np.array(xp_fly_pos_data)[idx_sort,:]\n",
    "                    \n",
    "                    # Only convert x, y pos positions to mm\n",
    "                    dict_pos_data[xp + fly][:,:2] *= 38/832\n",
    "                else:\n",
    "                    n_trials -= 1\n",
    "            \n",
    "        n_trial_data[strain] = n_trials\n",
    "        \n",
    "        print(f'{strain}: {n_trials} trials')\n",
    "    \n",
    "    return dict_pretarsi_data, dict_metadata, dict_pos_data, n_trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDN - Data dimension: (28770, 70)\n",
      "MDN - Metadata dimension: (28770, 6)\n",
      "MDN: 12 trials\n",
      "SS01049 - Data dimension: (26385, 70)\n",
      "SS01049 - Metadata dimension: (26385, 6)\n",
      "SS01049: 11 trials\n",
      "SS01054 - Data dimension: (31162, 70)\n",
      "SS01054 - Metadata dimension: (31162, 6)\n",
      "SS01054: 13 trials\n",
      "SS01540 - Data dimension: (26361, 70)\n",
      "SS01540 - Metadata dimension: (26361, 6)\n",
      "SS01540: 11 trials\n",
      "SS02111 - Data dimension: (26396, 70)\n",
      "SS02111 - Metadata dimension: (26396, 6)\n",
      "SS02111: 11 trials\n",
      "SS02279 - Data dimension: (28776, 70)\n",
      "SS02279 - Metadata dimension: (28776, 6)\n",
      "SS02279: 12 trials\n",
      "SS02377 - Data dimension: (28764, 70)\n",
      "SS02377 - Metadata dimension: (28764, 6)\n",
      "SS02377: 12 trials\n",
      "SS02608 - Data dimension: (28740, 70)\n",
      "SS02608 - Metadata dimension: (28740, 6)\n",
      "SS02608: 12 trials\n",
      "SS02617 - Data dimension: (26355, 70)\n",
      "SS02617 - Metadata dimension: (26355, 6)\n",
      "SS02617: 11 trials\n"
     ]
    }
   ],
   "source": [
    "raw_pretarsi_data, raw_metadata, _, n_trial_data = get_data_per_fly_per_xp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some keys to test\n",
    "mdn = '200206_1539540'\n",
    "turn = '200212_1620432'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findOnPeriods(key, raw_metadata, display=False):\n",
    "    '''\n",
    "    Find On-Stimulation periods for a given experiment\n",
    "    \n",
    "    Parameters\n",
    "    ------\n",
    "    key\n",
    "        Experiment key\n",
    "    \n",
    "    raw_metadata\n",
    "        Raw metadata for each fly in each experiment\n",
    "    \n",
    "    display\n",
    "        If true, displays on-stimulation intervals\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    numpy.ndarray\n",
    "        All frames where the stimulation was ON\n",
    "    '''\n",
    "    \n",
    "    metadata = raw_metadata[key]\n",
    "    on_periods = ['on0', 'on1', 'on2']\n",
    "\n",
    "    on_intervals = []\n",
    "\n",
    "    for p in on_periods:\n",
    "        start_period = np.where(metadata[:,1] == p)[0][0]\n",
    "        end_period = np.where(metadata[:,1] == p)[0][-1]\n",
    "        on_intervals.extend(list(range(start_period, end_period)))\n",
    "        if display:\n",
    "            print(f'{p}: {[start_period, end_period]}')\n",
    "    return np.array(on_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findStimulationData(raw_pretarsi_data, raw_metadata):\n",
    "    '''\n",
    "    Extract data where the stimulation was ON\n",
    "    \n",
    "    raw_pretarsi_data\n",
    "        Raw xy data for each pretarsus, size Lx12 for each fly\n",
    "    \n",
    "    raw_metadata\n",
    "        Corresponding metadata, size Lx6 for each fly\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    stim_data\n",
    "        XY stimulation data for each pretarsus, size lx12 for each fly, l < L\n",
    "    '''\n",
    "    stim_data = {}\n",
    "    \n",
    "    for key, data in raw_pretarsi_data.items():\n",
    "        on_idxs = findOnPeriods(key, raw_metadata)\n",
    "        \n",
    "        stim_data[key] = data[on_idxs,:]\n",
    "        \n",
    "    return stim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildStimulationArray(stim_data, nCoords=2):\n",
    "    '''\n",
    "    Build array from dictionary data containg stimulation xy positions for each fly\n",
    "    \n",
    "    stim_data\n",
    "        Dictionary of \"on\" xy data for each fly\n",
    "    \n",
    "    nCoords\n",
    "        Parameter to adjust size of matrix\n",
    "        nCoords = 2 if no wavelet transformation is applied\n",
    "        nCoords = 40 else\n",
    "    \n",
    "    Returns\n",
    "    stim_array\n",
    "        Transformation of stim_data into a numpy array: size Nx(l*K)\n",
    "        N: number of flies\n",
    "        l: number of on-stimulation frames\n",
    "        K: number of features\n",
    "    '''\n",
    "    \n",
    "    nLegs = 6\n",
    "    min_nFrames = stim_data[min(stim_data, key=lambda x: stim_data[x].shape[0])].shape[0]\n",
    "    \n",
    "    stim_array = np.zeros((len(stim_data), min_nFrames*nLegs*nCoords))\n",
    "    \n",
    "    for i, (key, data) in enumerate(stim_data.items()):\n",
    "        stim_array[i,:] = data[:min_nFrames,:].flatten()\n",
    "    \n",
    "    return stim_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stim_data = findStimulationData(raw_pretarsi_data, raw_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findWavelets(stim_data):\n",
    "    '''\n",
    "    Apply wavelet transformation\n",
    "    \n",
    "    We used 20 frequencies from 1 to 40 Hz, 40 being the Nyquist frequency (Frame rate: 80 fps)\n",
    "    \n",
    "    Parameters\n",
    "    ------\n",
    "    stim_data\n",
    "        A dictionary with raw data for each fly\n",
    "        key = experiment + fly index (according to tracking video)\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    wavelet_data\n",
    "        A dictionary with wavelet transform of data for each fly\n",
    "    '''\n",
    "    \n",
    "    wavelet_data = {}\n",
    "\n",
    "    n_scales = 20\n",
    "    fps = 80\n",
    "    f_min = 1\n",
    "    f_max = fps/2\n",
    "    #logvar_thresh = -6.\n",
    "\n",
    "    for (key, data) in stim_data.items():\n",
    "        wavelet_data[key] = np.zeros((list(data.shape) + [n_scales]))\n",
    "\n",
    "        # Wavelet transformation\n",
    "        for i in range(data.shape[1]):\n",
    "            sig = abs(signal.cwt(data[:,i], signal.morlet2, np.geomspace(f_min, f_max, n_scales)).T)\n",
    "\n",
    "            wavelet_data[key][:,i,:] = sig\n",
    "\n",
    "        wavelet_data[key] = wavelet_data[key].reshape(wavelet_data[key].shape[0], wavelet_data[key].shape[1]*wavelet_data[key].shape[2])\n",
    "\n",
    "        # Frame-normalization\n",
    "        for t in range(wavelet_data[key].shape[0]):\n",
    "            wavelet_data[key][t,:] = wavelet_data[key][t,:]/(wavelet_data[key][t,:].sum())\n",
    "    \n",
    "    return wavelet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_data = findWavelets(stim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build array from wavelet data\n",
    "stim_array = buildStimulationArray(wavelet_data, nCoords=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract classes for each fly (1 = MDN, 2 = SS01049...)\n",
    "\n",
    "classes = [] # List of colours attributed to each strain for later plotting\n",
    "strains = [] # Strain corresponding to each fly\n",
    "unique_classes = [] # Unique version of 'classes'\n",
    "\n",
    "for i, key in enumerate(n_trial_data.keys()):\n",
    "    #print(i)\n",
    "    #print(n_trial_data[key])\n",
    "    #print(n_trial_data[key] * [i])\n",
    "    unique_classes.append(sns.color_palette()[i])\n",
    "    for j in range(n_trial_data[key]):\n",
    "        classes.append(sns.color_palette()[i])\n",
    "        strains.append(key)\n",
    "unique_classes = np.array(unique_classes)\n",
    "classes = np.array(classes)\n",
    "strains = np.array(strains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 168960)\n"
     ]
    }
   ],
   "source": [
    "# Embed stimulation array in a 2D spaceusing TSNE\n",
    "print(stim_array.shape)\n",
    "embedded_array = TSNE(n_components=2).fit_transform(stim_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5e5259dc398d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Joint distribution plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjointplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedded_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"kde\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Clear the axes containing the scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "g = sns.jointplot(embedded_array[:,0], embedded_array[:,1], kind=\"kde\")\n",
    "\n",
    "#Clear the axes containing the scatter plot\n",
    "g.ax_joint.cla()\n",
    "\n",
    "# set the current axis to be the joint plot's axis\n",
    "plt.sca(g.ax_joint)\n",
    "\n",
    "# plt.scatter takes a 'c' keyword for color\n",
    "# you can also pass an array of floats and use the 'cmap' keyword to\n",
    "# convert them into a colormap\n",
    "sc = plt.scatter(embedded_array[:,0], embedded_array[:,1], c=classes, label=strains)\n",
    "lp = lambda i: plt.plot([], color=unique_classes[i], mec=\"none\",\n",
    "                        label=list(n_trial_data.keys())[i], ls=\"\", marker=\"o\")[0]\n",
    "handles = [lp(i) for i in np.arange(len(np.unique(strains)))]\n",
    "plt.legend(handles=handles, ncol=2, prop={'size': 8})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
